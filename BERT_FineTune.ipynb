{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "folder_path = \"/content/AI_Policy_Thesis\"  # Update the path if it's located elsewhere\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"The directory {folder_path} and all its contents have been deleted.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"The directory {folder_path} does not exist.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set to a valid working directory\n",
    "os.chdir(\"/content\")  # Default directory in Colab\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB GIT CLONE\n",
    "!git clone https://github.com/JochemBus/AI_Policy_Thesis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)  # Show full column content\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>gender_bias</th>\n",
       "      <th>sexual_bias</th>\n",
       "      <th>religion_bias</th>\n",
       "      <th>race_bias</th>\n",
       "      <th>disability_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1047401</td>\n",
       "      <td>Yo this guy is LAME! I would be so frustrated ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6129125</td>\n",
       "      <td>As Jehovah's Witnesses do not believe in blood...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>929666</td>\n",
       "      <td>You can read stuff like that in the Old Testam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5114785</td>\n",
       "      <td>It's_Harry_Mudd_in_reverse.__A._Everything_the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5255907</td>\n",
       "      <td>Hmmm but in the Gospel Jesus tells us to eat H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6347</th>\n",
       "      <td>4986948</td>\n",
       "      <td>In the RCC ALL authority, pronouncements, cano...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6348</th>\n",
       "      <td>524509</td>\n",
       "      <td>Does anyone else see the pattern of promises b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6349</th>\n",
       "      <td>972988</td>\n",
       "      <td>Dismantling of all government including those ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>5450450</td>\n",
       "      <td>We got Girls Gone Wild and Georgia got Hog Wild</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>5772874</td>\n",
       "      <td>EN,  Help me out, were the \"NAZIs, KKK and whi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6352 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                       comment_text  gender_bias  \\\n",
       "0     1047401  Yo this guy is LAME! I would be so frustrated ...            0   \n",
       "1     6129125  As Jehovah's Witnesses do not believe in blood...            0   \n",
       "2      929666  You can read stuff like that in the Old Testam...            0   \n",
       "3     5114785  It's_Harry_Mudd_in_reverse.__A._Everything_the...            0   \n",
       "4     5255907  Hmmm but in the Gospel Jesus tells us to eat H...            0   \n",
       "...       ...                                                ...          ...   \n",
       "6347  4986948  In the RCC ALL authority, pronouncements, cano...            1   \n",
       "6348   524509  Does anyone else see the pattern of promises b...            0   \n",
       "6349   972988  Dismantling of all government including those ...            0   \n",
       "6350  5450450    We got Girls Gone Wild and Georgia got Hog Wild            1   \n",
       "6351  5772874  EN,  Help me out, were the \"NAZIs, KKK and whi...            0   \n",
       "\n",
       "      sexual_bias  religion_bias  race_bias  disability_bias  \n",
       "0               0              0          0                0  \n",
       "1               0              0          0                0  \n",
       "2               0              0          0                0  \n",
       "3               0              0          0                0  \n",
       "4               0              1          0                0  \n",
       "...           ...            ...        ...              ...  \n",
       "6347            0              1          0                0  \n",
       "6348            1              0          0                0  \n",
       "6349            0              1          0                0  \n",
       "6350            0              0          0                0  \n",
       "6351            0              0          1                0  \n",
       "\n",
       "[6352 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_df = pd.read_csv(\"/content/AI_Policy_Thesis/filtered_bias_data.csv\")\n",
    "#bias_df = pd.read_csv(\"filtered_bias_data.csv\")\n",
    "\n",
    "bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "bias_df, bias_eval = train_test_split(bias_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Length Distribution:\n",
      "count    1000.000000\n",
      "mean      105.684000\n",
      "std        67.400972\n",
      "min         4.000000\n",
      "25%        47.000000\n",
      "50%        90.000000\n",
      "75%       161.250000\n",
      "max       304.000000\n",
      "Name: token_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token_distribution_df = pd.DataFrame()\n",
    "# Compute the token length for each comment\n",
    "# Using `encode` adds special tokens by default (e.g., [CLS], [SEP])\n",
    "token_distribution_df['token_length'] = bias_df['comment_text'].apply(\n",
    "    lambda x: len(tokenizer.encode(x, add_special_tokens=True))\n",
    ")\n",
    "\n",
    "print(\"Token Length Distribution:\")\n",
    "print(token_distribution_df['token_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize with a max token count of 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bias_df[\"tokenized\"] = bias_df[\"comment_text\"].apply(lambda text: tokenizer(\n",
    "    text, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    max_length=128,\n",
    "    add_special_tokens=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>gender_bias</th>\n",
       "      <th>sexual_bias</th>\n",
       "      <th>religion_bias</th>\n",
       "      <th>race_bias</th>\n",
       "      <th>disability_bias</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834937</th>\n",
       "      <td>660215</td>\n",
       "      <td>We have no obligation to foist our idea of wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993611</th>\n",
       "      <td>696994</td>\n",
       "      <td>Putting aside the exaggerated and unrealistic ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971119</th>\n",
       "      <td>5963512</td>\n",
       "      <td>So when the NEXT plan was released and the pub...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927678</th>\n",
       "      <td>6333555</td>\n",
       "      <td>Which you should normally get from your mother...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355238</th>\n",
       "      <td>5635048</td>\n",
       "      <td>Sigh. You're such an absolutist, Prog. Unable ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643400</th>\n",
       "      <td>6325215</td>\n",
       "      <td>I would be surprised if Francis acted on somet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856435</th>\n",
       "      <td>6076350</td>\n",
       "      <td>I'm not so sure about that. Yusra Khogali has ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834711</th>\n",
       "      <td>6113346</td>\n",
       "      <td>This is nothing more than a staged distraction...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834537</th>\n",
       "      <td>7044877</td>\n",
       "      <td>Story does not specify what \"ill\"\\nToo ill to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834693</th>\n",
       "      <td>6314052</td>\n",
       "      <td>The new mayor of Montreal, Val√©rie Plante, won...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                       comment_text  \\\n",
       "1834937   660215  We have no obligation to foist our idea of wha...   \n",
       "1993611   696994  Putting aside the exaggerated and unrealistic ...   \n",
       "1971119  5963512  So when the NEXT plan was released and the pub...   \n",
       "1927678  6333555  Which you should normally get from your mother...   \n",
       "1355238  5635048  Sigh. You're such an absolutist, Prog. Unable ...   \n",
       "...          ...                                                ...   \n",
       "1643400  6325215  I would be surprised if Francis acted on somet...   \n",
       "1856435  6076350  I'm not so sure about that. Yusra Khogali has ...   \n",
       "1834711  6113346  This is nothing more than a staged distraction...   \n",
       "1834537  7044877  Story does not specify what \"ill\"\\nToo ill to ...   \n",
       "1834693  6314052  The new mayor of Montreal, Val√©rie Plante, won...   \n",
       "\n",
       "         gender_bias  sexual_bias  religion_bias  race_bias  disability_bias  \\\n",
       "1834937            0            1              0          0                0   \n",
       "1993611            0            0              0          1                0   \n",
       "1971119            1            0              0          0                0   \n",
       "1927678            0            0              0          0                0   \n",
       "1355238            0            0              1          1                0   \n",
       "...              ...          ...            ...        ...              ...   \n",
       "1643400            0            0              0          0                0   \n",
       "1856435            1            0              0          1                0   \n",
       "1834711            0            0              1          0                0   \n",
       "1834537            0            0              0          0                0   \n",
       "1834693            1            0              1          0                0   \n",
       "\n",
       "                                           tokenized  \n",
       "1834937  [input_ids, token_type_ids, attention_mask]  \n",
       "1993611  [input_ids, token_type_ids, attention_mask]  \n",
       "1971119  [input_ids, token_type_ids, attention_mask]  \n",
       "1927678  [input_ids, token_type_ids, attention_mask]  \n",
       "1355238  [input_ids, token_type_ids, attention_mask]  \n",
       "...                                              ...  \n",
       "1643400  [input_ids, token_type_ids, attention_mask]  \n",
       "1856435  [input_ids, token_type_ids, attention_mask]  \n",
       "1834711  [input_ids, token_type_ids, attention_mask]  \n",
       "1834537  [input_ids, token_type_ids, attention_mask]  \n",
       "1834693  [input_ids, token_type_ids, attention_mask]  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2057, 2031, 2053, 14987, 2000, 1042, 10054, 2102, 2256, 2801, 1997, 2054, 2057, 5136, 2000, 2022, 1996, 4602, 2204, 2006, 2619, 2842, 1012, 10262, 2057, 2024, 7149, 2007, 6001, 1010, 2002, 2030, 2016, 2097, 2471, 5121, 24501, 4765, 2115, 19960, 14423, 1010, 2004, 2092, 2002, 2030, 2016, 2323, 1012, 2009, 1005, 1055, 3141, 2000, 2054, 6031, 1998, 4435, 17580, 1010, 1999, 2037, 3720, 1010, 1000, 1996, 2157, 2000, 9394, 1000, 2170, 1000, 1996, 2157, 2000, 2022, 2292, 2894, 1000, 1012, 2017, 2031, 4445, 1996, 2157, 4496, 1996, 4611, 2000, 2022, 1037, 5697, 23684, 1012, 2061, 1010, 2292, 2033, 9377, 2026, 3160, 1024, 2054, 2079, 2017, 2156, 2024, 1996, 5704, 1997, 5637, 2015, 1029, 4919, 1010, 2054, 5704, 2079, 2027, 2031, 2008, 1045, 1010, 2004, 1037, 28229, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_df[\"tokenized\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BiasDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Use the precomputed tokenized data\n",
    "        # We assume that `row['tokenized']` is a dictionary-like object containing:\n",
    "        #   - \"input_ids\"\n",
    "        #   - \"token_type_ids\" (if applicable)\n",
    "        #   - \"attention_mask\"\n",
    "        tokenized = row['tokenized']\n",
    "        \n",
    "        # Convert each element to a torch tensor\n",
    "        input_ids = torch.tensor(tokenized['input_ids'])\n",
    "        attention_mask = torch.tensor(tokenized['attention_mask'])\n",
    "        \n",
    "        # Some tokenizers might not include token_type_ids if not needed.\n",
    "        if 'token_type_ids' in tokenized:\n",
    "            token_type_ids = torch.tensor(tokenized['token_type_ids'])\n",
    "        else:\n",
    "            token_type_ids = None\n",
    "        \n",
    "        # Create a tensor for the 5 bias labels (using float for BCEWithLogitsLoss)\n",
    "        labels = torch.tensor([\n",
    "            row['gender_bias'],\n",
    "            row['sexual_bias'],\n",
    "            row['religion_bias'],\n",
    "            row['race_bias'],\n",
    "            row['disability_bias']\n",
    "        ], dtype=torch.float)\n",
    "        \n",
    "        # Return a dictionary that will be used as model inputs.\n",
    "        if token_type_ids is not None:\n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'token_type_ids': token_type_ids,\n",
    "                'labels': labels\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'labels': labels\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BiasDataset(bias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "num_labels = 5\n",
    "\n",
    "# Create a configuration tailored for multi-label classification\n",
    "config = BertConfig.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=num_labels, \n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Load the pre-trained model with the custom configuration\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    \n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version reported by PyTorch:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/AI_Policy_Thesis/results\",            # Directory to save model checkpoints\n",
    "    run_name = \"BERT_FineTune\",\n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=8,    # Batch size per device (GPU/CPU)\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"no\"           # Set to \"steps\" or \"epoch\" if you add an eval dataset\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=bias_eval,\n",
    ")\n",
    "\n",
    "print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17/375 02:00 < 47:58, 0.12 it/s, Epoch 0.13/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\transformers\\trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\transformers\\trainer.py:2553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m   2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[0;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m-> 2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2554\u001b[0m ):\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
