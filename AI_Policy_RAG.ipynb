{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 65 documents.\n",
      "page_content='Country: CHL\n",
      "Document number: 1\n",
      "Sentence: POLTICA NACIONAL DE INTELIGENCIA ARTIFICIALPOLTICA NACIONAL DE INTELIGENCIA ARTIFICIALCOMIT DE EXPERTOSCOORDINACIN REDACCIN Y EDICIN COMUNICACIONES  Y DISEOCOMIT INTERMINISTERIAL Marcelo ArenasPontificia Universidad Catlica de Chile e IM Fundamentos de los Datos Nstor BecerraUniversidad de Chile Raphael BergoeingUniversidad de Chile y Comisin Nacional de Productividad Alberto CerdaUniversidad de Chile Aisn EtcheverryAgencia Nacional de Investigacin y DesarrolloJos A' metadata={'type': 'document text', 'source': 'RAG_data/documents_text.json'}\n"
     ]
    }
   ],
   "source": [
    "def load_bias_terms(file_path: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Load the bias terms JSON file and return a list of Document objects.\n",
    "    \n",
    "    Each document will contain the bias type and its description.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    documents = []\n",
    "    for entry in data:\n",
    "        bias_type = entry.get(\"Bias_Type\", \"Unknown Bias\")\n",
    "        description = entry.get(\"Description\", \"\")\n",
    "        content = f\"Bias: {bias_type}\\nDescription: {description}\"\n",
    "        documents.append(Document(page_content=content, metadata={\"type\":\"definition\", \"source\": file_path}))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def load_document_text(file_path: str) -> list[Document]:\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    documents = []\n",
    "    for entry in data:\n",
    "        country = entry.get(\"country\", \"Unknown country\")\n",
    "        doc_nr = entry.get(\"document_nr\", \"\")\n",
    "        text_chunk = entry.get(\"text\", \"\")\n",
    "        content = f\"Country: {country}\\nDocument number: {doc_nr}\\nSentence: {text_chunk}\"\n",
    "        documents.append(Document(page_content=content, metadata={\"type\":\"document text\", \"source\": file_path}))\n",
    "    return documents\n",
    "    \n",
    "\n",
    "\n",
    "# Example usage:\n",
    "bias_documents = load_bias_terms(\"RAG_data/bias_terms.json\")\n",
    "text_documents = load_document_text(\"RAG_data/documents_text.json\")\n",
    "\n",
    "print(f\"Loaded {len(bias_documents)} documents.\")\n",
    "print(text_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT tokenizer (using the 'bert-base-uncased' model)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# A simple function to load a JSON file and convert it to a LangChain Document.\n",
    "def load_json_to_document(file_path: str) -> Document:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    # Assume the JSON contains a field \"text\". If not, convert the whole JSON to a string.\n",
    "    text = data.get(\"text\", str(data))\n",
    "    return Document(page_content=text, metadata={\"source\": file_path})\n",
    "\n",
    "# List your JSON file paths\n",
    "doc_paths = [\"doc1.json\", \"doc2.json\", \"doc3.json\"]\n",
    "\n",
    "# Load documents from the JSON files\n",
    "documents = [load_json_to_document(path) for path in doc_paths]\n",
    "\n",
    "# Optional: Function to tokenize a document with BERT and split into smaller chunks if needed.\n",
    "def tokenize_document(doc: Document, max_tokens: int = 128):\n",
    "    tokens = tokenizer.tokenize(doc.page_content)\n",
    "    # If the document is longer than max_tokens, split it into chunks.\n",
    "    if len(tokens) > max_tokens:\n",
    "        chunks = []\n",
    "        for i in range(0, len(tokens), max_tokens):\n",
    "            chunk_tokens = tokens[i:i+max_tokens]\n",
    "            chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
    "            chunks.append(Document(page_content=chunk_text, metadata=doc.metadata))\n",
    "        return chunks\n",
    "    else:\n",
    "        return [doc]\n",
    "\n",
    "# Process each document (this step is optional if you don't require chunking)\n",
    "processed_docs = []\n",
    "for doc in documents:\n",
    "    processed_docs.extend(tokenize_document(doc))\n",
    "\n",
    "# Initialize HuggingFace embeddings (you can choose a model based on your needs)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a FAISS vector store from the processed documents\n",
    "vectorstore = FAISS.from_documents(processed_docs, embeddings)\n",
    "\n",
    "# Convert the vectorstore into a retriever (here, returning the top-3 nearest neighbors)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Initialize your LLM (OpenAI's model in this case; ensure your API key is set in your environment)\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create the RetrievalQA (RAG) chain tying the retriever and the LLM together\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "# Query the RAG system\n",
    "query = \"What are the key points discussed in the documents?\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected page_content is string, got <class 'dict'> instead.                     Set `text_content=False` if the desired input for                     `page_content` is not a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m document_metrics_loader \u001b[38;5;241m=\u001b[39m JSONLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAG_data/document_metrics.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, jq_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m documents_text_loader \u001b[38;5;241m=\u001b[39m JSONLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAG_data/documents_text.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, jq_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m bias_terms \u001b[38;5;241m=\u001b[39m \u001b[43mbias_terms_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#document_metrics = document_metrics_loader.load()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#documents_text = documents_text_loader.load()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Combine the documents into one list\u001b[39;00m\n\u001b[0;32m     10\u001b[0m documents \u001b[38;5;241m=\u001b[39m bias_terms \u001b[38;5;241m+\u001b[39m document_metrics \u001b[38;5;241m+\u001b[39m documents_text\n",
      "File \u001b[1;32mc:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\langchain_community\\document_loaders\\json_loader.py:147\u001b[0m, in \u001b[0;36mJSONLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m                     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\langchain_community\\document_loaders\\json_loader.py:162\u001b[0m, in \u001b[0;36mJSONLoader._parse\u001b[1;34m(self, content, index)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_content_key(data)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 162\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata(\n\u001b[0;32m    164\u001b[0m         sample\u001b[38;5;241m=\u001b[39msample, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path), seq_num\u001b[38;5;241m=\u001b[39mi\n\u001b[0;32m    165\u001b[0m     )\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[1;32mc:\\Users\\busjo\\Documents\\JADS\\Thesis\\AI_Policy_Thesis\\venv\\Lib\\site-packages\\langchain_community\\document_loaders\\json_loader.py:180\u001b[0m, in \u001b[0;36mJSONLoader._get_text\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m    177\u001b[0m     content \u001b[38;5;241m=\u001b[39m sample\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_content \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m content \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected page_content is string, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124m            Set `text_content=False` if the desired input for \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124m            `page_content` is not a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# In case the text is None, set it to an empty string\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;31mValueError\u001b[0m: Expected page_content is string, got <class 'dict'> instead.                     Set `text_content=False` if the desired input for                     `page_content` is not a string"
     ]
    }
   ],
   "source": [
    "bias_terms_loader = JSONLoader(\"RAG_data/bias_terms.json\", jq_schema=\".[] | {page_content: .Description, metadata: {Bias_Type: .Bias_Type}}\")\n",
    "document_metrics_loader = JSONLoader(\"RAG_data/document_metrics.json\", jq_schema=\".\")\n",
    "documents_text_loader = JSONLoader(\"RAG_data/documents_text.json\", jq_schema=\".\")\n",
    "\n",
    "bias_terms = bias_terms_loader.load()\n",
    "#document_metrics = document_metrics_loader.load()\n",
    "#documents_text = documents_text_loader.load()\n",
    "\n",
    "# Combine the documents into one list\n",
    "documents = bias_terms + document_metrics + documents_text\n",
    "\n",
    "# Initialize HuggingFaceEmbeddings with a BERT model.\n",
    "# This will automatically use the BERT tokenizer from Hugging Face.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"bert-base-uncased\")\n",
    "\n",
    "# Build a FAISS vectorstore from the documents\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Initialize your LLM and set up the RetrievalQA chain\n",
    "llm = OpenAI(temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "# Run a query\n",
    "query = \"What are the most important types biases discussed in the USA policy documents\"\n",
    "result = qa_chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
